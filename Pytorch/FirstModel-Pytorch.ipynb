{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "# download \n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)\n",
    "# open datasets\n",
    "with gzip.open('data/mnist/mnist.pkl.gz', \"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADjBJREFUeJzt3X+MVfWZx/HPoy1EpRi1WRxFl26DTRqjg4zEP8jKumvjIgk0RoUYh6bNDn+UxJqNqdpRSdaNjVE2aiKRKimsLFBFAzbr0i5jtE1M44isP7eVbagdHBkRI0NMZIVn/7iHzaBzv+dy77n3nJnn/Uomc+957rnn8Tofzj33e+75mrsLQDynlN0AgHIQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQX2lkxszM04nBNrM3a2Rx7W05zeza8zs92a2x8xub+W5AHSWNXtuv5mdKukPkq6WNCTpFUnL3P3txDrs+YE268Sef56kPe7+R3c/ImmzpMUtPB+ADmol/OdL+vOY+0PZshOYWZ+ZDZrZYAvbAlCwtn/g5+5rJa2VeNsPVEkre/59ki4Yc39mtgzABNBK+F+RNNvMvmFmUyQtlbS9mLYAtFvTb/vd/XMzWylph6RTJa1z97cK6wxAWzU91NfUxjjmB9quIyf5AJi4CD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IqqNTdGPymTt3brK+cuXKurXe3t7kuhs2bEjWH3nkkWR9165dyXp07PmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiWZuk1s72SRiUdlfS5u/fkPJ5ZeieY7u7uZH1gYCBZnz59epHtnOCTTz5J1s8555y2bbvKGp2lt4iTfP7G3Q8U8DwAOoi3/UBQrYbfJf3KzF41s74iGgLQGa2+7Z/v7vvM7C8k/drM/tvdXxr7gOwfBf5hACqmpT2/u+/Lfo9IelbSvHEes9bde/I+DATQWU2H38zOMLOvHb8t6TuS3iyqMQDt1crb/hmSnjWz48/zb+7+H4V0BaDtWhrnP+mNMc5fOfPmfelI7QRbt25N1s8777xkPfX3NTo6mlz3yJEjyXreOP78+fPr1vK+65+37SprdJyfoT4gKMIPBEX4gaAIPxAU4QeCIvxAUAz1TQKnn3563dpll12WXPfJJ59M1mfOnJmsZ+d51JX6+8obbrv//vuT9c2bNyfrqd76+/uT6953333JepUx1AcgifADQRF+ICjCDwRF+IGgCD8QFOEHgmKK7kngscceq1tbtmxZBzs5OXnnIEybNi1Zf/HFF5P1BQsW1K1dcsklyXUjYM8PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzj8BzJ07N1m/9tpr69byvm+fJ28s/bnnnkvWH3jggbq1999/P7nua6+9lqx//PHHyfpVV11Vt9bq6zIZsOcHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaByr9tvZuskLZI04u4XZ8vOlrRF0ixJeyXd4O7pQVdx3f56uru7k/WBgYFkffr06U1v+/nnn0/W864HcOWVVybrqe/NP/7448l1P/zww2Q9z9GjR+vWPv300+S6ef9deXMOlKnI6/b/XNI1X1h2u6Sd7j5b0s7sPoAJJDf87v6SpINfWLxY0vrs9npJSwruC0CbNXvMP8Pdh7PbH0iaUVA/ADqk5XP73d1Tx/Jm1iepr9XtAChWs3v+/WbWJUnZ75F6D3T3te7e4+49TW4LQBs0G/7tkpZnt5dL2lZMOwA6JTf8ZrZJ0suSvmVmQ2b2A0k/lXS1mb0r6e+y+wAmkNxx/kI3FnSc/6KLLkrW77nnnmR96dKlyfqBAwfq1oaHh+vWJOnee+9N1p9++ulkvcpS4/x5f/dbtmxJ1m+66aameuqEIsf5AUxChB8IivADQRF+ICjCDwRF+IGguHR3AaZOnZqspy5fLUkLFy5M1kdHR5P13t7eurXBwcHkuqeddlqyHtWFF15Ydgttx54fCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinL8Ac+bMSdbzxvHzLF68OFnPm0YbGA97fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+AqxevTpZN0tfSTlvnJ5x/Oacckr9fduxY8c62Ek1secHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaByx/nNbJ2kRZJG3P3ibNkqSf8g6cPsYXe6+7+3q8kqWLRoUd1ad3d3ct286aC3b9/eVE9IS43l5/0/2b17d9HtVE4je/6fS7pmnOX/4u7d2c+kDj4wGeWG391fknSwA70A6KBWjvlXmtnrZrbOzM4qrCMAHdFs+NdI+qakbknDkh6s90Az6zOzQTNLTxoHoKOaCr+773f3o+5+TNLPJM1LPHatu/e4e0+zTQIoXlPhN7OuMXe/K+nNYtoB0CmNDPVtkrRA0tfNbEjSPZIWmFm3JJe0V9KKNvYIoA1yw+/uy8ZZ/EQbeqm01Dz2U6ZMSa47MjKSrG/ZsqWpnia7qVOnJuurVq1q+rkHBgaS9TvuuKPp554oOMMPCIrwA0ERfiAowg8ERfiBoAg/EBSX7u6Azz77LFkfHh7uUCfVkjeU19/fn6zfdtttyfrQ0FDd2oMP1j0jXZJ0+PDhZH0yYM8PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzt8BkS/Nnbqsed44/Y033pisb9u2LVm/7rrrkvXo2PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8zfIzJqqSdKSJUuS9VtuuaWpnqrg1ltvTdbvuuuuurUzzzwzue7GjRuT9d7e3mQdaez5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo3HF+M7tA0gZJMyS5pLXu/pCZnS1pi6RZkvZKusHdP25fq+Vy96ZqknTuuecm6w8//HCyvm7dumT9o48+qlu74oorkuvefPPNyfqll16arM+cOTNZf++99+rWduzYkVz30UcfTdbRmkb2/J9L+kd3/7akKyT90My+Lel2STvdfbakndl9ABNEbvjdfdjdd2W3RyW9I+l8SYslrc8etl5S+jQ2AJVyUsf8ZjZL0hxJv5M0w92PzzP1gWqHBQAmiIbP7TezaZK2SvqRux8aez67u7uZjXvga2Z9kvpabRRAsRra85vZV1UL/kZ3fyZbvN/MurJ6l6SR8dZ197Xu3uPuPUU0DKAYueG32i7+CUnvuPvqMaXtkpZnt5dLSl9KFUClWN4wlZnNl/QbSW9IOpYtvlO14/5fSLpQ0p9UG+o7mPNc6Y1V2PXXX1+3tmnTprZue//+/cn6oUOH6tZmz55ddDsnePnll5P1F154oW7t7rvvLrodSHL39HfMM7nH/O7+W0n1nuxvT6YpANXBGX5AUIQfCIrwA0ERfiAowg8ERfiBoHLH+Qvd2AQe5099dfWpp55Krnv55Ze3tO28S4O38v8w9XVgSdq8eXOyPpEvOz5ZNTrOz54fCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinL8AXV1dyfqKFSuS9f7+/mS9lXH+hx56KLnumjVrkvU9e/Yk66gexvkBJBF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8wOTDOP8AJIIPxAU4QeCIvxAUIQfCIrwA0ERfiCo3PCb2QVm9oKZvW1mb5nZLdnyVWa2z8x2Zz8L298ugKLknuRjZl2Sutx9l5l9TdKrkpZIukHSYXd/oOGNcZIP0HaNnuTzlQaeaFjScHZ71MzekXR+a+0BKNtJHfOb2SxJcyT9Llu00sxeN7N1ZnZWnXX6zGzQzAZb6hRAoRo+t9/Mpkl6UdI/u/szZjZD0gFJLumfVDs0+H7Oc/C2H2izRt/2NxR+M/uqpF9K2uHuq8epz5L0S3e/OOd5CD/QZoV9scdql459QtI7Y4OffRB43HclvXmyTQIoTyOf9s+X9BtJb0g6li2+U9IySd2qve3fK2lF9uFg6rnY8wNtVujb/qIQfqD9+D4/gCTCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAULkX8CzYAUl/GnP/69myKqpqb1XtS6K3ZhXZ2182+sCOfp//Sxs3G3T3ntIaSKhqb1XtS6K3ZpXVG2/7gaAIPxBU2eFfW/L2U6raW1X7kuitWaX0VuoxP4DylL3nB1CSUsJvZteY2e/NbI+Z3V5GD/WY2V4zeyObebjUKcayadBGzOzNMcvONrNfm9m72e9xp0krqbdKzNycmFm61NeuajNed/xtv5mdKukPkq6WNCTpFUnL3P3tjjZSh5ntldTj7qWPCZvZX0s6LGnD8dmQzOx+SQfd/afZP5xnufuPK9LbKp3kzM1t6q3ezNLfU4mvXZEzXhehjD3/PEl73P2P7n5E0mZJi0voo/Lc/SVJB7+weLGk9dnt9ar98XRcnd4qwd2H3X1XdntU0vGZpUt97RJ9laKM8J8v6c9j7g+pWlN+u6RfmdmrZtZXdjPjmDFmZqQPJM0os5lx5M7c3ElfmFm6Mq9dMzNeF40P/L5svrtfJunvJf0we3tbSV47ZqvScM0aSd9UbRq3YUkPltlMNrP0Vkk/cvdDY2tlvnbj9FXK61ZG+PdJumDM/ZnZskpw933Z7xFJz6p2mFIl+49Pkpr9Him5n//n7vvd/ai7H5P0M5X42mUzS2+VtNHdn8kWl/7ajddXWa9bGeF/RdJsM/uGmU2RtFTS9hL6+BIzOyP7IEZmdoak76h6sw9vl7Q8u71c0rYSezlBVWZurjeztEp+7So347W7d/xH0kLVPvH/H0k/KaOHOn39laT/yn7eKrs3SZtUexv4v6p9NvIDSedI2inpXUn/KensCvX2r6rN5vy6akHrKqm3+aq9pX9d0u7sZ2HZr12ir1JeN87wA4LiAz8gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0H9H/00nuWz++2XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1].reshape((28, 28)), cmap=\"gray\")\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elbio/.virtualenvs/cursos/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# convert to tensor\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "\n",
    "bs = 64  # batch size\n",
    "\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "yb = y_train[0:bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-73-2ed7e16072e0>\u001b[0m(5)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      4 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m        \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xb.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-73-2ed7e16072e0>\u001b[0m(6)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      5 \u001b[0;31m        \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 6 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2218e+00, -1.3036e+00,  7.3657e-01, -3.9584e-01, -8.7247e-01,\n",
      "          4.6080e-01,  1.7612e-01,  2.2583e-01, -2.0577e-01, -4.6679e-01],\n",
      "        [-3.7799e-01, -8.6325e-01,  2.6104e-01, -3.4748e-01, -3.8710e-01,\n",
      "          1.2103e+00, -6.6818e-01, -1.3690e+00,  3.3121e+00,  3.7038e-02],\n",
      "        [-1.1721e+00, -8.6678e-01, -7.7506e-01,  3.3797e+00, -7.2596e-01,\n",
      "          9.4780e-01, -1.7496e+00, -1.3694e-01,  7.3621e-01,  3.7022e-01],\n",
      "        [-4.3112e-01,  1.1725e+00,  8.3526e-01,  2.8282e-01, -9.6204e-01,\n",
      "          2.0567e-01, -9.6152e-01, -7.0126e-01,  1.2491e+00, -2.6185e-01],\n",
      "        [-4.1682e-01, -1.4055e+00,  4.2883e-01, -2.4452e-01, -4.3970e-03,\n",
      "          7.6206e-02,  3.7383e+00, -2.1693e+00,  1.9534e-01, -2.4607e-03],\n",
      "        [-1.0234e+00,  3.0629e+00,  9.4557e-01,  3.5161e-01, -1.3651e+00,\n",
      "         -1.1833e-01, -5.7704e-01, -1.1376e+00,  1.1452e+00, -1.0109e+00],\n",
      "        [-8.3163e-01, -6.5129e-01,  5.5845e-01, -7.1427e-01,  1.0269e+00,\n",
      "         -5.0944e-01,  9.5527e-01, -2.4584e-01, -3.5808e-01,  5.4282e-02],\n",
      "        [ 4.2206e+00, -1.9359e+00, -2.5638e-01,  9.5615e-01, -1.5873e+00,\n",
      "          1.7712e+00, -1.9561e+00,  1.7496e-01,  7.2142e-01, -4.7960e-01],\n",
      "        [-1.1404e+00, -2.1941e+00,  1.0513e+00,  3.0934e-02,  1.2312e+00,\n",
      "         -7.2330e-02,  1.2069e+00, -9.2959e-01,  7.8635e-01,  6.0660e-01],\n",
      "        [-9.3029e-01,  2.4936e+00, -4.1106e-02, -9.3034e-02, -9.7801e-01,\n",
      "         -3.5564e-02,  8.9651e-02, -2.2286e-01,  2.5611e-01, -2.4149e-01],\n",
      "        [-1.5424e+00,  3.2506e+00,  5.3150e-02,  2.2286e-01, -1.1802e+00,\n",
      "         -1.3178e-01, -2.3884e-01, -2.4751e-01,  8.0084e-02, -1.9700e-01],\n",
      "        [-9.0631e-01, -6.2908e-01, -6.8814e-01, -4.7868e-01,  2.9173e-01,\n",
      "         -2.5212e-01, -8.3391e-01,  2.2364e+00, -3.6198e-01,  1.2297e+00],\n",
      "        [ 3.9211e+00, -1.7219e+00,  1.7107e-01,  1.0179e+00, -1.0925e+00,\n",
      "          1.4677e+00,  4.8346e-01, -1.4168e+00, -4.7787e-01, -1.6864e+00],\n",
      "        [-9.5597e-01, -2.8964e-01,  5.4039e-01, -1.0528e+00,  1.0197e+00,\n",
      "         -9.3963e-01,  4.8792e-01,  1.4365e-01,  9.1095e-02,  8.0555e-01],\n",
      "        [-8.4052e-01, -1.4462e-02, -1.8294e-01, -3.9415e-01, -4.2954e-01,\n",
      "         -2.4227e-01, -2.2422e+00,  2.2235e+00,  1.3468e+00,  4.1126e-01],\n",
      "        [-3.4763e-01, -1.8456e+00, -2.0508e-01, -2.4239e+00,  3.1182e+00,\n",
      "         -5.6406e-01,  1.8030e+00, -4.3307e-01, -4.3493e-02,  7.6267e-01],\n",
      "        [-1.2591e+00,  8.5478e-01,  1.9844e+00, -1.0792e-01,  4.8984e-01,\n",
      "         -5.0274e-01, -8.6498e-01, -1.5462e+00,  1.8761e+00, -6.0904e-01],\n",
      "        [-1.2139e+00, -6.9675e-01,  5.3160e-01,  7.4590e-01, -3.1592e-01,\n",
      "          7.7348e-01, -3.0514e-01, -1.2521e+00,  2.3533e+00, -5.8643e-01],\n",
      "        [-1.8030e+00,  5.2317e-01, -1.6533e+00,  4.5276e-01, -1.9132e-02,\n",
      "          7.2496e-01, -4.5487e-01,  3.3931e-01,  6.4095e-01,  1.3760e+00],\n",
      "        [-1.3564e+00,  6.7227e-01,  3.2040e-01,  8.1531e-01, -7.3224e-01,\n",
      "          8.2046e-02, -1.4032e-01, -6.8688e-01,  1.2894e+00, -4.5995e-01],\n",
      "        [-1.3008e+00,  1.6583e+00,  2.2381e+00,  2.8925e-02, -1.2796e+00,\n",
      "         -7.5646e-01,  1.5444e+00, -8.2326e-01,  3.8078e-01, -7.3426e-01],\n",
      "        [-7.7029e-01, -4.5926e-01, -4.9011e-01,  6.0813e-01, -8.4247e-01,\n",
      "          1.4993e+00, -6.7636e-01,  5.6597e-01,  3.6248e-01, -2.2888e-02],\n",
      "        [-1.0792e+00,  4.8991e-01,  7.0691e-01, -1.2883e+00,  5.6119e-01,\n",
      "         -8.1657e-01, -2.1708e-01,  9.5689e-02,  9.6166e-01,  5.5868e-01],\n",
      "        [ 2.8912e+00, -1.2483e+00,  4.4177e-02, -8.9020e-01, -4.8451e-01,\n",
      "          1.9452e+00,  1.7181e+00, -1.9406e+00,  1.0393e-01, -1.2351e+00],\n",
      "        [-6.5800e-01,  1.0140e-01,  7.7034e-01,  7.5317e-02, -2.1017e-01,\n",
      "         -5.8874e-01, -8.7093e-01,  8.2035e-01,  6.5190e-01,  3.8791e-01],\n",
      "        [-1.2015e+00, -6.1607e-02,  6.3716e-01,  4.0379e-01,  1.5661e-01,\n",
      "          3.8014e-01, -6.0877e-01, -8.0386e-01,  1.2198e+00, -4.7484e-03],\n",
      "        [-1.6782e+00,  2.6426e+00, -1.9277e-01,  2.2566e-01, -1.0581e+00,\n",
      "          1.0811e-01,  1.9827e-01, -2.8330e-01,  1.6217e-01,  9.2945e-03],\n",
      "        [-6.3667e-01, -4.9133e-02, -3.5197e-01,  2.6827e+00, -8.4006e-01,\n",
      "          5.1395e-01, -1.8728e+00,  2.2422e-02,  9.8709e-01, -1.6847e-01],\n",
      "        [-3.8906e-01, -1.6017e+00,  1.0370e+00, -1.3348e+00,  7.1820e-01,\n",
      "         -1.6750e-01,  4.0875e+00, -2.0960e+00, -3.3553e-01, -2.1647e-01],\n",
      "        [-1.7265e+00, -1.2904e+00, -1.4685e+00, -4.1750e-01,  1.1909e+00,\n",
      "         -2.6912e-01, -1.6379e+00,  3.7751e+00, -2.6761e-01,  1.8232e+00],\n",
      "        [-1.3051e+00,  4.5917e-01,  1.8273e-01,  6.4202e-01, -6.7305e-01,\n",
      "          1.4366e-01, -1.7726e+00, -4.8490e-01,  2.8176e+00,  3.6063e-01],\n",
      "        [-6.8341e-01, -4.0867e-01,  1.6023e+00, -1.1826e+00,  1.0325e+00,\n",
      "         -1.1193e+00,  2.2501e+00, -9.0819e-01,  3.5187e-01, -5.6309e-02],\n",
      "        [-8.9387e-01,  2.5487e+00,  2.1975e-01, -2.8905e-02, -1.2400e+00,\n",
      "         -1.3146e-01, -5.6085e-03, -5.8337e-01,  4.0497e-01, -3.5600e-01],\n",
      "        [-1.4239e+00, -1.5994e+00, -8.5358e-01,  7.2782e-02,  1.2347e+00,\n",
      "         -1.7504e-01, -1.0952e+00,  1.3965e+00,  1.0708e-01,  2.5427e+00],\n",
      "        [-1.6653e+00,  1.0288e+00, -1.2162e+00,  1.4986e-01, -2.0084e-02,\n",
      "          4.0463e-01, -4.3895e-01,  9.1369e-02,  5.2122e-01,  1.0275e+00],\n",
      "        [-1.5600e+00,  6.6704e-01,  3.3182e-01,  1.0506e+00, -5.0183e-01,\n",
      "         -5.9605e-02, -5.4176e-01, -7.3623e-01,  1.7221e+00,  9.3856e-02],\n",
      "        [-1.3809e+00,  2.6145e+00, -1.6285e-01,  1.1722e-01, -8.1242e-01,\n",
      "         -3.9074e-02,  5.1303e-02, -2.6677e-01,  8.6964e-02, -1.0301e-01],\n",
      "        [ 4.1930e-01, -1.0665e+00, -8.2553e-01, -1.5002e-01,  1.9052e-01,\n",
      "          1.2994e+00,  1.4176e-01,  2.6921e-01, -5.8385e-01, -6.1181e-02],\n",
      "        [-1.0101e+00, -1.7144e+00, -1.4693e+00, -6.5249e-01,  1.7840e+00,\n",
      "          3.2451e-01, -6.3902e-01,  1.2817e+00, -3.1575e-01,  2.3929e+00],\n",
      "        [-6.7045e-01, -1.6697e+00,  3.2017e+00, -7.1448e-01, -6.9244e-01,\n",
      "         -5.2352e-01,  9.6755e-02,  7.9702e-01,  1.0587e+00,  3.8167e-02],\n",
      "        [ 1.0096e+00, -2.3022e+00,  1.9342e-01,  4.5908e-01, -6.9124e-02,\n",
      "          1.5603e+00, -1.5814e+00, -8.1884e-01,  1.8566e+00,  3.4414e-01],\n",
      "        [-8.5212e-01,  1.4334e+00,  5.1264e-01,  1.0093e-01, -8.0859e-01,\n",
      "          2.6831e-01, -1.3992e+00, -4.4204e-01,  2.1035e+00, -5.3940e-01],\n",
      "        [-1.4834e-01,  3.3365e-01,  1.5960e+00,  9.3628e-01, -1.0696e+00,\n",
      "          8.3592e-02, -6.5675e-01, -1.0582e+00,  1.4376e+00, -1.2529e+00],\n",
      "        [ 8.2068e-01, -1.9284e+00,  2.9638e+00,  6.8554e-01, -5.6870e-01,\n",
      "         -5.1602e-01,  3.3902e-01, -5.0978e-01,  5.9396e-02, -5.6015e-01],\n",
      "        [-1.5742e+00,  2.8201e+00, -1.0405e-01,  7.1023e-03, -8.5094e-01,\n",
      "         -3.2845e-01,  2.5298e-02,  6.7016e-02, -1.4217e-02, -3.8543e-02],\n",
      "        [-7.1152e-01,  1.8104e+00, -1.2258e+00, -1.5839e-01, -1.1000e+00,\n",
      "          6.4250e-01, -8.7105e-01,  5.2750e-01,  6.6203e-01,  6.2511e-01],\n",
      "        [-1.4270e+00, -5.9706e-02, -2.0900e-01,  3.8263e-01, -2.9099e-01,\n",
      "          1.2907e-01,  1.1710e+00, -8.8929e-01,  5.3403e-01,  1.4788e-01],\n",
      "        [ 5.0792e-01,  2.1493e-01, -6.4573e-02, -4.9451e-01,  1.1590e-01,\n",
      "          1.1191e+00, -4.7655e-01, -4.0394e-01,  6.0843e-01, -7.4000e-01],\n",
      "        [-6.2216e-01,  2.6104e-01, -6.6308e-01, -8.1379e-01,  5.5756e-01,\n",
      "          2.7301e-02, -6.8707e-01,  1.3706e+00,  2.8517e-01,  1.7134e-01],\n",
      "        [-1.1712e+00, -1.2910e+00,  1.3715e-01,  2.1331e-01,  4.3306e-01,\n",
      "          8.2457e-01,  2.0589e+00, -1.8438e+00,  6.2939e-01, -1.4652e-01],\n",
      "        [-3.5101e-01, -3.9357e-01, -9.3760e-01,  3.7213e-01, -5.3371e-01,\n",
      "          7.9440e-01,  1.6685e-01,  1.9806e-01, -4.5027e-02,  9.1749e-02],\n",
      "        [-8.9764e-01,  2.2135e+00,  1.7389e-01,  3.0288e-01, -7.9884e-01,\n",
      "         -2.2032e-01, -8.5618e-01, -4.5290e-01,  6.2895e-01, -3.6734e-01],\n",
      "        [ 5.8194e-01, -1.1001e+00, -7.1804e-01,  1.1283e+00, -6.9897e-01,\n",
      "          7.7865e-01, -9.4966e-01,  5.1298e-01,  8.8600e-01, -7.5981e-02],\n",
      "        [-7.7863e-01, -1.5291e+00, -2.9202e-01,  1.2532e+00, -4.5506e-01,\n",
      "         -3.8436e-01, -1.0984e+00,  3.0123e+00, -6.8542e-01,  8.2147e-01],\n",
      "        [ 4.7283e+00, -2.1533e+00, -5.5258e-01, -4.4882e-01, -1.2590e+00,\n",
      "          2.4571e+00, -4.1683e-01, -5.3653e-01, -1.4240e-01, -1.1825e+00],\n",
      "        [-6.7575e-01, -5.4584e-01, -9.8719e-02, -3.8814e-01,  2.3401e-01,\n",
      "         -1.7917e-01, -5.7471e-01,  1.1308e+00, -7.3104e-02,  1.1683e+00],\n",
      "        [-9.7554e-02, -1.0234e+00,  3.0952e-01, -1.1591e+00, -3.6501e-01,\n",
      "          6.8580e-01, -5.9772e-01,  3.9844e-01,  1.8212e+00,  3.8567e-01],\n",
      "        [ 3.6262e-02, -1.3314e+00, -2.1901e+00,  5.2178e-01, -3.3968e-01,\n",
      "          2.3149e+00, -1.3940e+00,  4.4469e-01,  8.5807e-01,  1.0801e+00],\n",
      "        [-9.1357e-01,  3.9562e-01, -1.4913e-01, -1.2212e+00,  6.9614e-01,\n",
      "          2.2432e-01,  1.8838e-01, -6.1161e-01,  8.2526e-01,  6.0968e-02],\n",
      "        [ 1.0221e-01, -1.6503e+00, -2.2953e-02, -1.7255e+00,  9.2755e-01,\n",
      "         -2.3326e-01, -6.8966e-01,  8.0090e-01,  8.7500e-01,  1.7814e+00],\n",
      "        [-1.8116e-01,  4.3435e-01, -1.1949e+00, -7.8728e-01,  6.5449e-01,\n",
      "          9.6317e-01, -4.1533e-01,  1.7202e-01,  1.8334e-01,  1.8565e-01],\n",
      "        [-1.0329e+00, -1.8371e-01,  6.7178e-01,  5.5440e-01, -4.5988e-02,\n",
      "          2.6561e-02, -6.6145e-02, -1.0950e+00,  1.6571e+00, -4.7618e-01],\n",
      "        [-1.2447e+00, -4.5145e-01,  2.1266e+00, -8.6184e-01,  6.8543e-01,\n",
      "         -1.0282e+00,  1.6027e+00, -4.3799e-01, -2.6444e-01, -1.5561e-01],\n",
      "        [ 4.1718e-01, -1.4619e+00, -2.5095e-01, -1.6585e+00,  1.4737e+00,\n",
      "          2.5693e-01,  1.6150e+00, -7.7581e-01, -3.7014e-01,  1.3477e+00]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pred.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-73-2ed7e16072e0>\u001b[0m(8)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      7 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 8 \u001b[0;31m        \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m        \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9500, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-73-2ed7e16072e0>\u001b[0m(9)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      8 \u001b[0;31m        \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 9 \u001b[0;31m        \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m        \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        import ipdb;ipdb.set_trace()\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "\n",
    "    print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8974, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
